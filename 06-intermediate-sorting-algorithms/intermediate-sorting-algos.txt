the beginning sorting algorithms simply do not scale well

there is another family of algorithms that can improve time complexity from o(n^2) to O(n log n)
however there is a tradeoff between efficiency and simplicity
the more efficient algorithms are much less simple, and generally take longer to understand
lets dive in!


!!** M E R G E   S O R T **!!
- It's a combination between two things -- merging and sorting!
- Exploits the fact that array of 0 or 1 element are always sorted
- Works by decomposing an array into smaller arrays of 0 or 1 elements, then building up a newly sorted array

First step!
- First create or implement a function that is responible for merging two sorted arrays

Merging Arrays Pseudocode
- create an empty array, take a look at the smallest values in each input array (should be the first of both arrays because they're sorted)
- while there are still values we haven't looked at...
    - if the value in the first array is smaller than the value in the second array, push the value in the first array into our results and move on to the next value in the first array
    - if the value in the first array is large than the value in the second array, push the value in the second array into our results and move on to the next value in the second array
    - once we exhaust one array, push in all remaining values from the other array

BIG O For Merge sort
- Time Complexity (best), Time complexity (avg), Time Complexity(worst), 
    O(n log n)

Space Complexity:
    O(n)


!!** Q U I C K   S O R T **!!
- Bane of Colts existence in terms of sorting algorithms
- Like merge sort, explots the fact that arrays of 0 or 1 elements are always sorted
- Works by selecting one element(called the "pivot") and finding the index where the pivot should end up in the sorted array
- Whichever number is less than the pivot point, keep a counter that keeps track of how many are less, any number that is more than 11 we keep track of as well.
- Once we get to the end we know the exact index the pivot point should be at in the array, move it to that point and then recurse and start the process again

in order to implement merge sort, it's useful to first implement a function responsible arranging elements in an array on either side of a pivot
given an array, this helper function should designate an element as the 'pivot' point
it should then rearrange elements in the array so that all values greater than the pivot are moved to the right of the pivot
the order of elements on either side of the pivot doesn't matter!
the helper should do this IN PLACE, that is, it should not create a new array
when complete, the helper should return the correct index of the pivot

the runtime of quick sort depends in part on how one selects the pivot 
ideally, the pivot should be chosen so that it's roughly the median value in the data set you're sorting
for simplicity sake, we'll always choose the first pivot example


just like merge sort we need a helper function, in this case its the pivot helper function

Pivot Pseudocode
- It will help accept three arguments: an array, a start index, and an end index (these can default to 0 and the array length minus 1, respectively)
- Grab the pivot from the start of the array
- Store the current pivot index in a variable (this will keep track of where the pivot should up)
- Loop through the array from the start until the end
    -If the pivot is greater than the current element, increment the pivot index vairable and then swap the current element with the element with the element at the pivot index
- Swap the starting element with the pivot index
- Return the pivot index

Quicksort Pseudocode
- Call the pivot helper on the array
- When the helper returns to you the updated pivot index, recursively call the pivot helper on the subarray to the left of that index, and the subarray to the right of that index
- Your base case occurs when you consider a subarray with less than 2 elements


